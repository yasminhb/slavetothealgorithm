# week 7...lets start thinking about our projects

### In class activity

Using processing, we learnt how to use 'wiggle' which is pretty self explanatory, but it was actually really cool to see the letters move around the screen on their own.

We were also able to learn how to incorporate typing words onto our screen, and make that part of the interaction/visual. 

#### Here's an example of the processing activity we learnt:

<img src=https://github.com/yasminhb/slavetothealgorithm/blob/master/week%207/ezgif-7-3d98e925fa76.gif>

Eventually the letters start to wiggle around the screen so much that the original sentence you typed becomes completely distorted.

I really like the idea of visual distortion as I feel like it is such an interesting way to represent topics of corruption or confusion. 

Although I really liked this proessing sketch, I don't plan to use any typography in my project.

### Idea #1

I had a brainstorming session with Jinni where we discussed ideas of how we could take our projects further. We both agreed that it would be super cool to look into VR technology, as the user would be able to experience the digital enviroment I create and be completely immersed in it. 

After a little bit of research I shortly discovered that VR headsets are hundreds of dollars and I am a broke university student so that didn't seem like the best idea.

I then remembered when I was in highschool and was looking at different university open days, I saw multiple people handing out these cardboard VR sets that you could insert your phone into. 

#### Sort of like this:

*INSERT PHOTO*

This served as a cheap and way more accessible alternative to buying a professional headset. This way it meant that more people would be able to participate in the idea.

However, I realised that it would be difficult to incoporate face tracking into the algorithm and would probably need to rethink how I would be incorporating emotions into the idea.

### Idea #2

I had previously mentioned the possibilty of creating a digital garden in my presentation (during week 5), and thought it would be a good idea to expand upon it. I also wanted to explore how the idea of face tracking could be used, so Jinni, Alice and I started to look at other peoples processing sketches for inspiration.

We realised it was more than face tracking, but actully emotion tracking as well. 

After researching examples of emotion tracking from facial expressions we found most of them were done in Python, and started to become scared as 5 weeks was not enough time to learn another code language.

After a while we managed to find some that worked in processing!

#### Here are few cool examples of face tracking and emotion tracking in processing and p5.js

*INSERT PHOTO AND LINK*

*INSERT PHOTO AND LINK*

This gave me some piece of mind that it was actually possible to do this in processing, and learning a whole new code language wasn't needed.

My only concern then was 'HOW DO I ACTUALLY CONNECT THIS EMOTION TRACKING AS AN INPUT TO MY DIGITAL GARDEN?'.

### Prototyping my idea

I decided to expand upon Idea #2, as I felt this was more suited for my concept and would also be more fun to create in processing.

#### This is what my prototype looks like:

<img src=https://github.com/yasminhb/slavetothealgorithm/blob/master/week%207/Untitled_Artwork%202.gif>

Basically, the users facial expressions would be tracked using their web cam, and this would then be detected as different emotions. From here, the garden would live react to whatever emotions were being seen by the camera.

I decided it would be a little boring to just do 'if happy, sun will shine' or 'if sad, it will start raining'. Although that is a good example of how pathetic fallacy would be typically used in a novel, I wanted to switch it up a bit and make it more unpredictable and chaotic for the user (because I'm a mischevious person). 

Instead, I thought that the garden would react in an opposite manner to the facial expression. 

In real life, if plants get *too* much sun they start to dry up and die. Realistically, rain is actually really good for plants as it helps them flourish.

#### So...

If you smile too much and appear happy, the sun will appear and the digital garden will dry up and die. If you appear sad, it will start to rain and the garden will start to flourish.

### Making a pseudocode

To make my idea a little more clear, I had a go at writing a pseudocode

#### Here's what it looks like:

*INSERT PHOTO*

I'm not sure if it's correct, but I can always change it up as I go along with my project.

I also wasn't sure if I would have time to incorporate sound into my digital garden, but feel it would make the experience more sensory/immersive.

I feel like it will probably be my last step. If I have time to code it, I would like to include it for final touches.


